{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36268fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-of0zyraw\n",
      "  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-of0zyraw\n",
      "  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
      "  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: keras in ./venv/lib64/python3.11/site-packages (from keras-contrib==2.0.8) (2.12.0)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101058 sha256=e0ff085e273a2f441542b63b311bdb1e388e43eafcd7ee8bcc9ef99a8ff2a3a9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_l5g5gio/wheels/51/5f/dc/dade7fdf81085b847dde4bd2fa307f2e0f67a26400031d0c27\n",
      "Successfully built keras-contrib\n",
      "Installing collected packages: keras-contrib\n",
      "Successfully installed keras-contrib-2.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f83a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataloader\n",
      "  Downloading dataloader-2.0.tar.gz (9.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: dataloader\n",
      "  Building wheel for dataloader (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dataloader: filename=dataloader-2.0-py3-none-any.whl size=10084 sha256=ba0de1b6492802b613446fe14f69a28d8feffb5c3364dd99bf2744e2892d6300\n",
      "  Stored in directory: /home/sudokit/.cache/pip/wheels/c7/b4/28/bf711e4f9bf69d9fc21b1c017d9b63eb13c3a6f35308088a0b\n",
      "Successfully built dataloader\n",
      "Installing collected packages: dataloader\n",
      "Successfully installed dataloader-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c574bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading imageio-2.29.0-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./venv/lib64/python3.11/site-packages (from imageio) (1.23.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in ./venv/lib64/python3.11/site-packages (from imageio) (9.5.0)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.29.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "967995a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0a91daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "import scipy\n",
    "import imageio\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "\n",
    "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                img = scipy.misc.imresize(img, self.img_res)\n",
    "\n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            else:\n",
    "                img = scipy.misc.imresize(img, self.img_res)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.array(imgs)/127.5 - 1.\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n",
    "        path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n",
    "\n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "\n",
    "        # Sample n_batches * batch_size from each path list so that model sees all\n",
    "        # samples from both domains\n",
    "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "    def imread(self, path):\n",
    "        return imageio.imread(path, mode='RGB').astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d78bf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15500f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'apple2orange'\n",
    "        # Use the DataLoader object to import a preprocessed dataset\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 32\n",
    "        self.df = 64\n",
    "\n",
    "        # Loss weights\n",
    "        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n",
    "        self.lambda_id = 0.9 * self.lambda_cycle    # Identity loss\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        # Build and compile the discriminators\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "                         optimizer=optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "                         optimizer=optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "\n",
    "        # Input images from both domains\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        # Translate images back to original domain\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # Identity mapping of images\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generators\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,\n",
    "                                       img_A_id, img_B_id])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                              loss_weights=[1, 1,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id],\n",
    "                              optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0891f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    @staticmethod\n",
    "    def conv2d(layer_input, filters, f_size=4, normalization=True):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size,\n",
    "                   strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if normalization:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "      \n",
    "    @staticmethod\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "            u = InstanceNormalization()(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "        return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4aa47b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = self.conv2d(d0, self.gf)\n",
    "        d2 = self.conv2d(d1, self.gf * 2)\n",
    "        d3 = self.conv2d(d2, self.gf * 4)\n",
    "        d4 = self.conv2d(d3, self.gf * 8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = self.deconv2d(d4, d3, self.gf * 4)\n",
    "        u2 = self.deconv2d(u1, d2, self.gf * 2)\n",
    "        u3 = self.deconv2d(u2, d1, self.gf)\n",
    "\n",
    "        u4 = UpSampling2D(size=2)(u3)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4,\n",
    "                            strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e08351f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_discriminator(self):\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        d1 = self.conv2d(img, self.df, normalization=False)\n",
    "        d2 = self.conv2d(d1, self.df * 2)\n",
    "        d3 = self.conv2d(d2, self.df * 4)\n",
    "        d4 = self.conv2d(d3, self.df * 8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2ca806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "      def sample_images(self, epoch, batch_i):\n",
    "        r, c = 2, 3\n",
    "\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
    "        \n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        fake_A = self.g_BA.predict(imgs_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9c0cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "      def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # Total discriminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                      [valid, valid,\n",
    "                                                       imgs_A, imgs_B,\n",
    "                                                       imgs_A, imgs_B])\n",
    "                # If at save interval => plot the generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae061f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5721/4120950101.py:72: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return imageio.imread(path, mode='RGB').astype(np.float)\n",
      "/tmp/ipykernel_5721/4120950101.py:72: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return imageio.imread(path, mode='RGB').astype(np.float)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <f8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/College/Engineering/S6/BIAI/GANs/venv/lib64/python3.11/site-packages/PIL/Image.py:3089\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3088\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3089\u001b[0m     mode, rawmode \u001b[38;5;241m=\u001b[39m \u001b[43m_fromarray_typemap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtypekey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 3), '<f8')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cycle_gan \u001b[38;5;241m=\u001b[39m CycleGAN()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcycle_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 9\u001b[0m, in \u001b[0;36mCycleGAN.train\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m      5\u001b[0m fake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisc_patch)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_i, (imgs_A, imgs_B) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader\u001b[38;5;241m.\u001b[39mload_batch(batch_size)):\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m#  Train Discriminators\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Translate images to opposite domain\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         fake_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_AB\u001b[38;5;241m.\u001b[39mpredict(imgs_A)\n\u001b[1;32m     17\u001b[0m         fake_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_BA\u001b[38;5;241m.\u001b[39mpredict(imgs_B)\n",
      "Cell \u001b[0;32mIn[66], line 56\u001b[0m, in \u001b[0;36mDataLoader.load_batch\u001b[0;34m(self, batch_size, is_testing)\u001b[0m\n\u001b[1;32m     53\u001b[0m img_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimread(img_A)\n\u001b[1;32m     54\u001b[0m img_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimread(img_B)\n\u001b[0;32m---> 56\u001b[0m img_A \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_A\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresize(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_res)\n\u001b[1;32m     57\u001b[0m img_B \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img_B)\u001b[38;5;241m.\u001b[39mresize(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_res)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_testing \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/College/Engineering/S6/BIAI/GANs/venv/lib64/python3.11/site-packages/PIL/Image.py:3092\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3090\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3091\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot handle this data type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m typekey\n\u001b[0;32m-> 3092\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3094\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <f8"
     ]
    }
   ],
   "source": [
    "cycle_gan = CycleGAN()\n",
    "cycle_gan.train(epochs=100, batch_size=64, sample_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6f7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
